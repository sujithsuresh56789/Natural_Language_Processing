{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvTyk28yhfKMlnxmaWyjHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujithsuresh56789/Natural_Language_Processing/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize  # You may need to install nltk and download the punkt tokenizer\n",
        "\n",
        "# Example sentences (replace these with your own dataset)\n",
        "sentences = [\n",
        "    \"Word embeddings are awesome!\",\n",
        "    \"They provide a way to represent words as vectors.\",\n",
        "    \"These vectors capture semantic relationships between words.\",\n",
        "]\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"word2vec_model\")\n",
        "\n",
        "# You can load the model later with:\n",
        "# model = Word2Vec.load(\"word2vec_model\")\n",
        "\n",
        "# Get the vector for a specific word\n",
        "vector = model.wv['word']\n",
        "print(\"Vector for 'word':\", vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F6f22n0rbUZ",
        "outputId": "b3964d81-c39c-427d-9a91-85793d35bdf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for 'word': [ 5.6267120e-03  5.4973708e-03  1.8291199e-03  5.7494068e-03\n",
            " -8.9680776e-03  6.5593575e-03  9.2259916e-03 -4.2071473e-03\n",
            "  1.6075504e-03 -5.2338815e-03  1.0582185e-03  2.7701687e-03\n",
            "  8.1607364e-03  5.4401276e-04  2.5570584e-03  1.2977350e-03\n",
            "  8.4025227e-03 -5.7077026e-03 -6.2618302e-03 -3.6275184e-03\n",
            " -2.3005498e-03  5.0410628e-03 -8.1203571e-03 -2.8335357e-03\n",
            " -8.1974268e-03  5.1497100e-03 -2.5680638e-03 -9.0671070e-03\n",
            "  4.0717293e-03  9.0173231e-03 -3.0376601e-03 -5.8385395e-03\n",
            "  3.0198884e-03 -4.3584823e-04 -9.9794362e-03  8.4177041e-03\n",
            " -7.3388875e-03 -4.9304068e-03 -2.6570810e-03 -5.4523144e-03\n",
            "  1.7165100e-03  9.7128144e-03  4.5722723e-03  8.0886027e-03\n",
            " -4.7045827e-04  6.4492342e-04 -2.6683521e-03 -8.7795611e-03\n",
            "  3.4313034e-03  2.0933736e-03 -9.4218543e-03 -4.9684369e-03\n",
            " -9.7340988e-03 -5.7197916e-03  4.0645422e-03  8.6428607e-03\n",
            "  4.1116499e-03  2.3884643e-03  8.1447782e-03 -1.1192096e-03\n",
            " -1.3977134e-03 -8.7468233e-03 -1.2579202e-04 -2.5675725e-03\n",
            "  3.8607715e-04  7.2796619e-03 -7.0414604e-03 -3.9464748e-03\n",
            " -6.6646053e-03 -3.5441148e-03 -3.3158315e-03  2.1371210e-03\n",
            "  3.3281683e-03 -4.9571870e-03 -4.5462907e-03  1.1386942e-03\n",
            "  5.4534827e-03  5.3736498e-03 -2.9685367e-03 -4.2665256e-03\n",
            " -5.6166472e-03 -5.4498314e-04  1.9463730e-03  1.5253461e-03\n",
            "  7.3525296e-03 -2.7333724e-03 -6.5923930e-05 -5.5276332e-03\n",
            " -1.1700654e-03 -7.7119637e-03 -9.5932960e-04  1.3096749e-03\n",
            " -8.5947439e-03  8.7485835e-03 -9.2078662e-03 -9.6246768e-03\n",
            " -8.5116243e-03  7.3132683e-03  5.4655685e-03  9.2494618e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmSGCelcrmVi",
        "outputId": "38844b52-c522-4786-e04b-ae03b98e5818"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel=Word2Vec()"
      ],
      "metadata": {
        "id": "W1sJokPtrtIE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=[[\"Neeraj\",\"Boy\"],[\"Sarwan\",\"is\"],[\"good\",\"boy\"]]\n",
        "import gensim\n",
        "#training word2vec on 3 sentences\n",
        "model = gensim.models.Word2Vec(sentence, min_count=1,vector_size=300,workers=4)"
      ],
      "metadata": {
        "id": "68o6r875siF3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using the model\n",
        "#The new trained model can be used similar to the pre-trained ones.\n",
        "\n",
        "#printing similarity index\n",
        "print(model.wv.similarity('woman', 'man'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS_ILS90tAs5",
        "outputId": "15b75306-5f51-4ab0-8a1e-004c2500431b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.011825436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Training sentences\n",
        "sentences = [[\"Neeraj\", \"Boy\"], [\"Sarwan\", \"is\"], [\"good\", \"boy\"], [\"woman\", \"man\"]]\n",
        "\n",
        "# Training Word2Vec model\n",
        "model = Word2Vec(sentences, min_count=1, vector_size=300, workers=4)\n",
        "\n",
        "# Checking similarity between 'woman' and 'man'\n",
        "similarity_score = model.wv.similarity('woman', 'man')\n",
        "\n",
        "# Printing the similarity score\n",
        "print(f\"Similarity between 'woman' and 'man': {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFH1cqDftR2E",
        "outputId": "6040d4e0-6c8e-4486-c604-5adee34ec28a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'woman' and 'man': -0.011825435794889927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Loading the downloaded model\n",
        "model = Word2Vec.load('path/to/GoogleNews-vectors-negative300.bin')\n",
        "\n",
        "# Getting word vectors of a word\n",
        "dog_vector = model['dog']\n",
        "print(\"Vector for 'dog':\", dog_vector)\n",
        "\n",
        "# Performing king - man + woman = queen magic\n",
        "similar_words = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(\"Most similar word to 'woman' and 'king' (queen expected):\", similar_words[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "B1xP-j9Bt7ZT",
        "outputId": "a82722db-d0d5-4055-8e8e-dba9c1e47851"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-03249319215d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loading the downloaded model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Getting word vectors of a word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \"\"\"\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/GoogleNews-vectors-negative300.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "I193dpJtuTNe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mylist=[[\"sujith\",\"suresh\"],[\"man\",\"women\"]]\n",
        "mymodel=Word2Vec(mylist,vector_size=100,window=1,workers=4,min_count=1)"
      ],
      "metadata": {
        "id": "AU1NY89XuumS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel.wv.similarity(\"women\",\"man\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AobW1W_1vAwa",
        "outputId": "c68bc9f7-58ea-4b11-e4a3-cb6720fa8ea8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.010839177"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKOLKxDovUmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}